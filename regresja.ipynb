{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Mon, 13 Mar 2023   Prob (F-statistic):           1.58e-96\n",
      "Time:                        14:55:20   Log-Likelihood:                -422.65\n",
      "No. Observations:                 200   AIC:                             853.3\n",
      "Df Residuals:                     196   BIC:                             866.5\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.5267      0.374      9.422      0.000       2.789       4.265\n",
      "youtube        0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "facebook       0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         545.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "marketing = pd.read_excel(\"m.xlsx\", index_col=0)\n",
    "mod = ols(formula='sales ~ youtube + facebook + newspaper', data=marketing)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dep. Variable:                  sales\n",
    "To informacja wskazująca, która zmienna jest zależna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method:                 Least Squares\n",
    "Informacja o metodzie - domyślnie metoda najmniejszych kwadratów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. Observations:                 200\n",
    "Liczba obserwacji - w tym kontekście liczba wierszy (bez nagłówka)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Df Residuals:                     196\n",
    "Liczba stopni swobody reszt: liczby obserwacji minus liczbę zmiennych niezależnych w modelu (w tym stałej). Innymi słowy, jest to liczba niezależnych obserwacji, które mogą być użyte do oszacowania reszt modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Df Model:                           3\n",
    "Liczba stopni swobody modelu, czyli liczba zmiennych objaśniających (niezależnych, bez stałej), które zostały uwzględnione w modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance Type:            nonrobust\n",
    "Typ kowariancji użyty w estymacji macierzy wariancji-kowariancji parametrów modelu. W analizie regresji, estymacja macierzy kowariancji jest istotna, ponieważ pozwala na obliczenie błędów standardowych parametrów regresji, t-statystyk i przedziałów ufności.\n",
    "'nonrobust': standardowa estymacja kowariancji, która nie uwzględnia żadnych specjalnych właściwości danych.\n",
    "'HC0': metoda Hubera-White'a, która jest odporna na heteroskedastyczność i autokorelację reszt.\n",
    "'HC1', 'HC2', 'HC3': różne wersje metody Hubera-White'a, które różnią się wagami reszt wykorzystanymi w estymacji macierzy kowariancji.\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.get_robustcov_results.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared:                       0.897\n",
    "Miara dopasowania modelu liniowego do danych i wskazuje, jaka część zmienności zmiennej objaśnianej jest wyjaśniona przez zmienne objaśniające.\n",
    "R-kwadrat przyjmuje wartości od 0 do 1 i interpretuje się go jako procent wariancji zmiennej objaśnianej, która jest wyjaśniona przez model. Wartość R-kwadrat równe 0 oznacza, że model nie tłumaczy żadnej zmienności zmiennej objaśnianej, a wartość R-kwadrat równe 1 oznacza, że model tłumaczy całą zmienność zmiennej objaśnianej.\n",
    "\n",
    "Należy jednak pamiętać, że wysoka wartość R-kwadrat nie zawsze oznacza, że model jest dobry. W szczególności, jeśli model ma wiele zmiennych objaśniających, wysoka wartość R-kwadrat może być wynikiem przeuczenia (overfittingu) modelu. Dlatego, warto zawsze uwzględnić także inne statystyki wyników analizy regresji, takie jak błędy standardowe parametrów, wartości t-statystyk i p-wartości.\n",
    "\n",
    "$$R^2 = 1 - (SSR / SST)$$\n",
    "$$R^2 = (SSM / SST)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897210638178954\n",
      "0.8972106381789522\n"
     ]
    }
   ],
   "source": [
    "yh = res.predict() # z modelu\n",
    "y=np.array(marketing.iloc[:,3]) # dane do uczenia\n",
    "ym=np.mean(y)\n",
    "ssm=np.sum((yh-ym)**2)\n",
    "sst=np.sum((y-ym)**2)\n",
    "r2=ssm/sst\n",
    "print(r2)\n",
    "print(res.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adj. R-squared:                  0.896\n",
    "Skorygowane R-kwadrat jest miarą dopasowania modelu liniowego do danych, podobnie jak R-kwadrat, ale uwzględnia liczbę zmiennych objaśniających w modelu.\n",
    "Skorygowane R-kwadrat jest skorygowaną wersją R-kwadrat i uwzględnia liczbę zmiennych objaśniających w modelu oraz liczbę obserwacji. Im większa liczba zmiennych objaśniających, tym większa szansa na przeuczenie (overfitting) modelu i sztucznie wyższy R-kwadrat. Skorygowane R-kwadrat koryguje tę niedoskonałość poprzez penalizowanie złożoności modelu i jest bardziej odpowiednią miarą dopasowania modelu dla modeli z wieloma zmiennymi objaśniającymi.\n",
    "Skorygowane R-kwadrat przyjmuje wartości od 0 do 1 i interpretuje się go tak samo jak R-kwadrat - jako procent wariancji zmiennej objaśnianej, która jest wyjaśniona przez model. Wartość Skorygowanego R-kwadrat bliska 1 oznacza, że model dobrze wyjaśnia zmienność zmiennej objaśnianej, uwzględniając złożoność modelu.\n",
    "Wartość Skorygowanego R-kwadrat może być wyższa lub niższa niż R-kwadrat, w zależności od liczby zmiennych objaśniających w modelu i liczby obserwacji. Dlatego warto zawsze uwzględnić obie statystyki w analizie wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skorygowany współczynnik determinacji:\n",
    "\n",
    "$$\\overline{R}^2=1 - (1 - R^2) \\frac{n - 1}{n - p}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956373316204685\n",
      "0.8956373316204668\n"
     ]
    }
   ],
   "source": [
    "ro2=1-((1-r2)*(199/196))\n",
    "print(ro2)\n",
    "print(res.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-test dla regresji wielowymiarowej\n",
    "\n",
    "$$H_0: \\qquad   \\beta_1 = \\beta_2 = \\ldots = \\beta_{p-1} = 0$$\n",
    "\n",
    "$$H_1: \\qquad  \\beta_j \\neq 0 \\ \\mathrm{dla \\ co \\ najmniej \\ jednego} \\ j.$$\n",
    "Wyliczamy statystykę:\n",
    "\n",
    "$$F=\\frac{MSM}{MSE} = \\frac{\\mathrm{\"wyjaśniona \\ wariancja\"}}{\\mathrm{\"niewyjaśniona \\ wariancja\"}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6998.865821420864\n",
      "801.8283785791496\n",
      "7800.6942\n",
      "7800.6942000000145\n",
      "2332.9552738069547\n",
      "4.090961115199742\n",
      "39.199468341708545\n",
      "570.2707036590954\n",
      "570.2707036590942\n"
     ]
    }
   ],
   "source": [
    "ssm=np.sum((yh-ym)**2)\n",
    "print(ssm)\n",
    "ssr=np.sum((y-yh)**2)\n",
    "print(ssr)\n",
    "sst=np.sum((y-ym)**2)\n",
    "print(sst)\n",
    "print(ssm+ssr)\n",
    "msm=ssm/3\n",
    "print(msm)\n",
    "mse=ssr/196\n",
    "print(mse)\n",
    "mst=sst/199\n",
    "print(mst)\n",
    "fi=msm/mse\n",
    "print(fi)\n",
    "print(res.fvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statystyka ta podlega rozkładowi F-Snedecora z $p-1$ i $n-p$ stopniami swobody. Ustalamy $\\alpha=0,05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6506765101121412\n"
     ]
    }
   ],
   "source": [
    "print(f.ppf(0.95, 3, 196))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli wartość statystyki jest większa kwantylowi, odrzucamy hipotezę zerową. W przeciwnym wypadku przyjmujemy hipotezę zerową.\n",
    "\n",
    "W naszym wypadku odrzucamy hipotezę zerową. Innymi słowy, odrzucamy hipotezę że wydatki na reklamy na poszczególne media nie mają wpływu na sprzedaż.\n",
    "\n",
    "Obliczmy wartość $p$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5752272560922012e-96\n",
      "1.5752272560924532e-96\n"
     ]
    }
   ],
   "source": [
    "rv=f(3,196)\n",
    "print(rv.sf(fi))\n",
    "print(res.f_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W naszym wypadku jest to \"bliskie\" zeru, więc możemy przyjąć, że się zgadza.\n",
    "\n",
    "Jeśli $p\\leqslant \\alpha$ odrzucamy $H_0$ przyjmując $H_1$. W przeciwnym wypadku nie ma podstaw by odrzucić $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Log-Likelihood:                -422.65\n",
    "Log-Likelihood (logarytm funkcji wiarygodności) jest miarą dopasowania modelu do danych. Funkcja wiarygodności mierzy, jak dobrze model opisuje rozkład prawdopodobieństwa zmiennych objaśniających. Im większa wartość funkcji wiarygodności, tym lepiej model opisuje dane i lepiej pasuje do prawdziwego rozkładu danych. Logarytm funkcji wiarygodności jest ujemny, a większa wartość logarytmu oznacza lepsze dopasowanie modelu.\n",
    "Log-Likelihood jest często stosowany do porównywania różnych modeli, ponieważ można porównać wartości logarytmów funkcji wiarygodności różnych modeli. Można również obliczyć test logarytmu funkcji wiarygodności (log-likelihood ratio test), aby ocenić, czy jeden model jest lepszy od drugiego.\n",
    "\n",
    "Wzór:\n",
    "\n",
    "$$\\mathrm{Log-Likelihood} = -\\frac{1}{2} \\cdot n \\cdot \\ln(2 \\pi) - \\frac{1}{2} \\cdot n\\cdot  \\ln(\\sigma^2) - \\frac{1}{2} \\cdot \\frac{SSR}{\\sigma^2}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-422.645429303174\n"
     ]
    }
   ],
   "source": [
    "print(res.llf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.009141892895748\n",
      "-422.645429303174\n"
     ]
    }
   ],
   "source": [
    "sigma2 = np.sum(res.resid ** 2) / 200 ## warto sprawdzić, że sigma2 a nie s2\n",
    "print(sigma2)\n",
    "n= 200\n",
    "ll = -0.5 * n * np.log(2 * np.pi) - 0.5 * n * np.log(sigma2) - 0.5 * ssr / sigma2\n",
    "print(ll)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AIC:                             853.3\n",
    "AIC (Akaike's Information Criterion) st miarą, która uwzględnia jakość dopasowania modelu do danych oraz złożoność modelu, czyli liczbę zmiennych objaśniających.\n",
    "AIC mierzy, jak dobrze model opisuje dane, jednocześnie karząc za dodawanie dodatkowych zmiennych objaśniających do modelu, które mogą nie przynieść dodatkowej informacji. W przypadku AIC, mniejsza wartość oznacza lepszy model.\n",
    "AIC jest wyrażony w postaci liczby punktów, gdzie mniejsza liczba oznacza lepszy model. AIC można wykorzystać do porównywania różnych modeli i wybierania modelu, który najlepiej pasuje do danych.\n",
    "\n",
    "$$\\operatorname{AIC} = -2 \\cdot \\operatorname{Log-Likelihood} + 2 p$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853.290858606348\n",
      "853.290858606348\n"
     ]
    }
   ],
   "source": [
    "print(res.aic)\n",
    "aic = -2 * ll +2*4\n",
    "print(aic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BIC:                             866.5\n",
    "BIC (Bayesian Information Criterion) mierzy jakość dopasowania modelu do danych oraz jego złożoność, ale uwzględnia również liczbę obserwacji w próbie.\n",
    "BIC jest miarą, która jest oparta na teorii Bayesa i opiera się na koncepcji, że lepszy model jest bardziej prawdopodobny zgodnie z zasadą największego prawdopodobieństwa, ale powinien też mieć mniejszą liczbę parametrów.\n",
    "BIC jest wyrażony w postaci liczby punktów, gdzie mniejsza wartość oznacza lepszy model. BIC można wykorzystać do porównywania różnych modeli i wybierania modelu, który najlepiej pasuje do danych.\n",
    "\n",
    "$$\\operatorname{BIC} = -2 \\cdot \\operatorname{Log-Likelihood} + p\\cdot \\ln(n)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866.4841280725402\n",
      "866.4841280725402\n"
     ]
    }
   ],
   "source": [
    "print(res.bic)\n",
    "bic = -2 * ll + 4 * np.log(200)\n",
    "print(bic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Omnibus:                       60.414\n",
    "Omnibus to test normalności reszt w modelu regresji, który bada, czy reszty w modelu są rozłożone normalnie.\n",
    "Test Omnibus jest testem chi-kwadrat i ma dwie hipotezy:\n",
    "Hipoteza zerowa: Reszty w modelu mają rozkład normalny.\n",
    "Hipoteza alternatywna: Reszty w modelu nie mają rozkładu normalnego.\n",
    "\n",
    "Do ew. dokończenia (??)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3273536543621196\n",
      "3.3318912890624732\n",
      "Omnibus:  60.41395945525499\n",
      "P-value:  7.60808558322375e-14\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "skewness = stats.skew(res.resid)\n",
    "kurtosis = stats.kurtosis(res.resid)\n",
    "print(skewness)\n",
    "print(kurtosis)\n",
    "\n",
    "omnibus, p_value = stats.normaltest(res.resid)\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print('Omnibus: ', omnibus)\n",
    "print('P-value: ', p_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durbin-Watson:                   2.084\n",
    "Durbin-Watson to statystyka diagnostyczna, która służy do oceny autokorelacji reszt w modelu regresji liniowej. Autokorelacja reszt występuje, gdy występuje zależność między wartościami reszt w kolejnych obserwacjach.\n",
    "Statystyka Durbin-Watson przyjmuje wartości od 0 do 4 i pozwala na ocenę występowania autokorelacji reszt w modelu regresji. Wartość 2 oznacza brak autokorelacji, wartości poniżej 2 wskazują na występowanie dodatniej autokorelacji, a wartości powyżej 2 wskazują na występowanie ujemnej autokorelacji.\n",
    "\n",
    "Interpretacja wyniku Durbin-Watson może być następująca:\n",
    "\n",
    "Wartość Durbin-Watson bliska 2 wskazuje na brak autokorelacji reszt.\n",
    "Wartość Durbin-Watson mniejsza od 2 wskazuje na występowanie dodatniej autokorelacji reszt (czyli wartości reszt w kolejnych obserwacjach są skorelowane dodatnio).\n",
    "Wartość Durbin-Watson większa od 2 wskazuje na występowanie ujemnej autokorelacji reszt (czyli wartości reszt w kolejnych obserwacjach są skorelowane ujemnie).\n",
    "\n",
    "$$DW = \\sum_{i=2}^n [(r_i - r_{i-1})^2] / \\sum_{i=1}^n (r_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.083648405294408\n",
      "2.083648405294408\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(res.resid)\n",
    "print(dw)\n",
    "\n",
    "e=res.resid\n",
    "diff_e = np.diff(e)\n",
    "sum_sq_diff_e = np.sum(diff_e ** 2)\n",
    "sum_sq_e = np.sum(e ** 2)\n",
    "dw2 = sum_sq_diff_e / sum_sq_e\n",
    "print(dw2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jarque-Bera (JB):              151.241\n",
    "arque-Bera (JB) to test normalności rozkładu reszt w modelu regresji. Test Jarque-Bera wykorzystuje skośność (skewness) i kurtozę (kurtosis) rozkładu reszt, aby sprawdzić, czy rozkład ten jest zbliżony do rozkładu normalnego.\n",
    "Wynik testu Jarque-Bera to wartość chi-kwadrat (χ²) z dwoma stopniami swobody i odpowiada na pytanie, czy rozkład reszt w modelu regresji jest zbliżony do rozkładu normalnego. Wartość p-value dla testu Jarque-Bera pozwala na określenie, czy odrzucamy hipotezę o normalności rozkładu reszt (mała wartość p-value) czy nie (wysoka wartość p-value).\n",
    "Interpretacja wyniku testu Jarque-Bera może być następująca:\n",
    "Wartość chi-kwadrat bliska zeru i wysoka wartość p-value wskazują na brak istotnych odchyleń od rozkładu normalnego i odrzucenie hipotezy o niestandardowym rozkładzie reszt.\n",
    "Wartość chi-kwadrat dużo większa od zera i niska wartość p-value wskazują na duże odchylenie od rozkładu normalnego i odrzucenie hipotezy o normalności rozkładu reszt.\n",
    "\n",
    "$$JB = n/6 \\cdot (S^2 + 1/4 \\cdot (K - 3)^2)$$\n",
    "$$JB = n/6 \\cdot (S^2 + 1/4 \\cdot K^2)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.2414204760357\n",
      "1.4399347942411259e-33\n",
      "151.2414204760357\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from scipy.stats import chi2\n",
    "\n",
    "jb_stat, jb_pvalue, _, _ = jarque_bera(res.resid)\n",
    "print(jb_stat)\n",
    "print(jb_pvalue)\n",
    "\n",
    "n = 200\n",
    "JB = n / 6 * (skewness**2 + 1/4 * kurtosis **2)\n",
    "\n",
    "# wyznaczmy wartość krytyczną dla testu Jarque-Bera (z poziomem istotności alpha = 0.05 i dwoma stopniami swobody)\n",
    "alpha = 0.05\n",
    "df = 2\n",
    "JB_critical = chi2.ppf(1-alpha, df)\n",
    "pvalue = 1 - chi2.cdf(JB, df)\n",
    "print(JB)\n",
    "print(pvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cond. No.                         545.\n",
    "Cond. No. to liczba uwarunkowania macierzy w modelu regresji. Liczba uwarunkowania odzwierciedla stopień, w jakim zmiany w danych wejściowych (zmienne niezależne) wpływają na zmienność wyjścia (zmienna zależna) oraz na stabilność i dokładność wyników modelu regresji.\n",
    "\n",
    "Wartość Cond. No. wynosi zwykle od 1 (idealna sytuacja) do bardzo wysokich wartości (np. 100 lub więcej), co oznacza, że macierz w modelu regresji jest źle uwarunkowana i może prowadzić do problemów numerycznych lub niestabilności wyników.\n",
    "\n",
    "Liczba uwarunkowania jest szczególnie istotna w przypadku wielu zmiennych niezależnych lub silnie skorelowanych zmiennych niezależnych. W takich przypadkach zmiany w jednej zmiennej mogą prowadzić do znaczących zmian w innych zmiennych, co wpływa na stabilność wyników modelu regresji.\n",
    "\n",
    "Interpretacja wartości Cond. No. może być następująca:\n",
    "\n",
    "Wartość Cond. No. bliska 1 wskazuje na dobrze uwarunkowaną macierz i stabilne wyniki modelu regresji.\n",
    "Wartość Cond. No. większa od 1, ale mniejsza niż 100, wskazuje na pewne problemy z uwarunkowaniem macierzy, ale wyniki modelu regresji są wciąż dość stabilne.\n",
    "Wartość Cond. No. większa niż 100 wskazuje na poważne problemy z uwarunkowaniem macierzy i niestabilność wyników modelu regresji.\n",
    "\n",
    "$$Cond. No. = max(s) / min(s)$$\n",
    "\n",
    "s- wartości osobliwe macierzy\n",
    "\n",
    "Wartość osobliwa macierzy (singular value) to pojęcie z algebry liniowej odzwierciedlające \"siłę\" wektora w macierzy. W kontekście modelu regresji liniowej wartości osobliwe macierzy X określają wpływ poszczególnych zmiennych niezależnych na zmienność wyjścia (zmienną zależną) oraz umożliwiają wyznaczenie wartości Cond. No. macierzy X.\n",
    "\n",
    "Wartość osobliwa macierzy jest równa pierwiastkowi kwadratowemu z wartości własnych macierzy X.T * X lub X * X.T, z których jedna jest macierzą kowariancji, a druga macierzą korelacji. Wartości osobliwe macierzy są dodatnie i posortowane malejąco."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545.2331163467246\n",
      "[2946.18689305  478.23029185  233.39770042    5.40353622]\n",
      "545.2331163467246\n"
     ]
    }
   ],
   "source": [
    "one=np.ones((200,1))\n",
    "x=np.array(marketing.iloc[:,0:3])\n",
    "x=np.append(one,x,axis=1)\n",
    "print(np.linalg.cond(x))\n",
    "singular = np.linalg.svd(x, compute_uv=False)\n",
    "print(singular)\n",
    "cond_no = np.max(singular) / np.min(singular)\n",
    "print(cond_no)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2946.18689305  478.23029185  233.39770042    5.40353622]\n"
     ]
    }
   ],
   "source": [
    "C = np.dot(x.T, x)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "singular_values = np.sqrt(eigenvalues)\n",
    "singular_values_sorted = np.sort(singular_values)[::-1]\n",
    "print(singular_values_sorted)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
